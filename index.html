<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Stress & Expression Analyzer – Phase 2</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">

<style>
body{
  margin:0;
  background:#000;
  color:#00f0ff;
  font-family:monospace;
  overflow:hidden;
}
video, canvas{
  position:absolute;
  width:100vw;
  height:100vh;
  object-fit:cover;
}
canvas{pointer-events:none}
#ui{
  position:absolute;
  top:10px;
  left:10px;
  z-index:10;
  background:rgba(0,0,0,0.65);
  padding:12px;
  border-left:3px solid #00f0ff;
  font-size:12px;
}
.stat{color:#fff}
button{
  background:#001122;
  color:#00f0ff;
  border:1px solid #00f0ff;
  padding:5px 8px;
  margin-top:6px;
}
.warn{font-size:10px;color:#ff5555}
</style>
</head>

<body>

<div id="ui">
  <div><b>STRESS & EXPRESSION ANALYZER</b></div>
  <div>Camera: <span id="camLabel" class="stat">FRONT</span></div>
  <div>Expression: <span id="exprVal" class="stat">---</span></div>
  <div>Blinks/sec: <span id="blinkVal" class="stat">0</span></div>
  <div>Movement: <span id="moveVal" class="stat">0</span></div>
  <div>Stress Score: <span id="stressVal" class="stat">0</span></div>
  <button id="switchCam">Switch Camera</button>
  <div class="warn">⚠️ Experimental. Not a lie detector.</div>
</div>

<video id="video" autoplay playsinline muted></video>
<canvas id="overlay"></canvas>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>

<script>
/* ========= ELEMENTS ========= */
const video = document.getElementById("video");
const canvas = document.getElementById("overlay");
const ctx = canvas.getContext("2d");

const camLabel = document.getElementById("camLabel");
const blinkVal = document.getElementById("blinkVal");
const moveVal = document.getElementById("moveVal");
const stressVal = document.getElementById("stressVal");
const exprVal = document.getElementById("exprVal");

canvas.width = innerWidth;
canvas.height = innerHeight;

/* ========= CAMERA ========= */
let currentFacing = "user";
let stream = null;
let postureMode = false;

async function startCamera(){
  if(stream) stream.getTracks().forEach(t=>t.stop());
  stream = await navigator.mediaDevices.getUserMedia({
    video:{ facingMode: currentFacing, width:1280, height:720 },
    audio:false
  });
  video.srcObject = stream;
  await video.play();
}

document.getElementById("switchCam").onclick = ()=>{
  currentFacing = currentFacing === "user" ? "environment" : "user";
  camLabel.innerText = currentFacing === "user" ? "FRONT" : "BACK";
  postureMode = currentFacing === "environment";
  startCamera();
};

/* ========= FACEMESH ========= */
const faceMesh = new FaceMesh({
  locateFile:f=>`https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}`
});
faceMesh.setOptions({
  maxNumFaces:1,
  refineLandmarks:true,
  minDetectionConfidence:0.6,
  minTrackingConfidence:0.6
});

/* ========= STATE ========= */
let blinkCount = 0;
let lastBlink = 0;
let prevHeadX = null;
let headMove = 0;

let prevFrame = null;
let motionScore = 0;

/* ========= POSTURE (BACK CAMERA) ========= */
function analyzePosture(){
  ctx.drawImage(video,0,0,canvas.width,canvas.height);
  const frame = ctx.getImageData(0,0,canvas.width,canvas.height);
  if(prevFrame){
    let diff=0;
    for(let i=0;i<frame.data.length;i+=40){
      diff+=Math.abs(frame.data[i]-prevFrame.data[i]);
    }
    motionScore = diff/100000;
  }
  prevFrame = frame;
}

/* ========= CORE ========= */
faceMesh.onResults(res=>{
  ctx.clearRect(0,0,canvas.width,canvas.height);

  if(postureMode){
    analyzePosture();
    moveVal.innerText = motionScore.toFixed(2);
    const stress = Math.min(100,Math.floor(motionScore*80));
    stressVal.innerText = stress;
    exprVal.innerText = "BODY MODE";
    return;
  }

  if(!res.multiFaceLandmarks) return;
  const lm = res.multiFaceLandmarks[0];

  /* ---- Blink ---- */
  const eyeTop = lm[159];
  const eyeBot = lm[145];
  const eyeDist = Math.abs(eyeTop.y-eyeBot.y);
  const now = performance.now();
  if(eyeDist<0.005 && now-lastBlink>300){
    blinkCount++;
    lastBlink=now;
  }

  /* ---- Head movement ---- */
  const nose = lm[1];
  if(prevHeadX!==null) headMove+=Math.abs(nose.x-prevHeadX);
  prevHeadX = nose.x;

  /* ---- Expression analysis ---- */
  const mouthOpen = Math.abs(lm[13].y - lm[14].y);
  const jawTension = Math.abs(lm[152].y - lm[13].y);
  const browLift = Math.abs(lm[70].y - lm[159].y);

  let expression="Neutral";
  if(blinkCount>3 && mouthOpen<0.01 && browLift<0.02){
    expression="Stressed";
  }else if(blinkCount<2 && mouthOpen>0.015){
    expression="Relaxed";
  }

  exprVal.innerText = expression;

  /* ---- Stress score ---- */
  let stress = blinkCount*8 + headMove*400;
  stress = Math.min(100,Math.floor(stress));

  blinkVal.innerText = blinkCount;
  moveVal.innerText = headMove.toFixed(3);
  stressVal.innerText = stress;

  /* ---- Debug draw ---- */
  ctx.fillStyle="#00f0ff";
  lm.forEach(p=>{
    ctx.fillRect(p.x*canvas.width-1,p.y*canvas.height-1,2,2);
  });

  if(now%1000<16){
    blinkCount=0;
    headMove=0;
  }
});

/* ========= LOOP ========= */
async function loop(){
  await faceMesh.send({image:video});
  requestAnimationFrame(loop);
}

/* ========= START ========= */
startCamera().then(loop);
</script>

</body>
</html>
