<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Stress / Confidence Analyzer – Phase 1</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">

<style>
body{
  margin:0;
  background:#000;
  color:#00f0ff;
  font-family:monospace;
  overflow:hidden;
}
video{
  position:absolute;
  width:100vw;
  height:100vh;
  object-fit:cover;
  z-index:1;
}
canvas{
  position:absolute;
  width:100vw;
  height:100vh;
  z-index:2;
  pointer-events:none;
}
#ui{
  position:absolute;
  top:10px;
  left:10px;
  z-index:10;
  background:rgba(0,0,0,0.65);
  padding:12px;
  border-left:3px solid #00f0ff;
  font-size:12px;
}
button{
  background:#001122;
  color:#00f0ff;
  border:1px solid #00f0ff;
  padding:5px 8px;
  margin-top:6px;
}
.stat{color:#fff}
</style>
</head>

<body>

<div id="ui">
  <div><b>STRESS ANALYZER (EXPERIMENTAL)</b></div>
  <div>Camera: <span id="camLabel" class="stat">FRONT</span></div>
  <div>Blinks/sec: <span id="blinkVal" class="stat">0</span></div>
  <div>Head Move: <span id="moveVal" class="stat">0</span></div>
  <div>Stress Score: <span id="stressVal" class="stat">0</span></div>
  <button id="switchCam">Switch Camera</button>
  <div style="font-size:10px;color:#ff5555;margin-top:6px">
    ⚠️ Not a lie detector. Experimental only.
  </div>
</div>

<video id="video" autoplay playsinline muted></video>
<canvas id="overlay"></canvas>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>

<script>
/* ========= ELEMENTS ========= */
const video = document.getElementById("video");
const canvas = document.getElementById("overlay");
const ctx = canvas.getContext("2d");

const blinkVal = document.getElementById("blinkVal");
const moveVal = document.getElementById("moveVal");
const stressVal = document.getElementById("stressVal");
const camLabel = document.getElementById("camLabel");

canvas.width = innerWidth;
canvas.height = innerHeight;

/* ========= CAMERA ========= */
let currentFacing = "user"; // user | environment
let stream = null;

async function startCamera(){
  if(stream){
    stream.getTracks().forEach(t=>t.stop());
  }
  stream = await navigator.mediaDevices.getUserMedia({
    video:{
      facingMode: currentFacing,
      width:1280,
      height:720
    },
    audio:false
  });
  video.srcObject = stream;
  await video.play();
}

document.getElementById("switchCam").onclick = ()=>{
  currentFacing = currentFacing === "user" ? "environment" : "user";
  camLabel.innerText = currentFacing === "user" ? "FRONT" : "BACK";
  startCamera();
};

/* ========= FACEMESH ========= */
const faceMesh = new FaceMesh({
  locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}`
});

faceMesh.setOptions({
  maxNumFaces:1,
  refineLandmarks:true,
  minDetectionConfidence:0.6,
  minTrackingConfidence:0.6
});

/* ========= ANALYSIS STATE ========= */
let lastBlinkTime = 0;
let blinkCount = 0;
let prevHeadX = null;
let headMovement = 0;

/* ========= CORE ========= */
faceMesh.onResults(res=>{
  ctx.clearRect(0,0,canvas.width,canvas.height);
  if(!res.multiFaceLandmarks) return;

  const lm = res.multiFaceLandmarks[0];

  /* ---- Blink detection (eye vertical distance) ---- */
  const eyeTop = lm[159];
  const eyeBottom = lm[145];
  const eyeDist = Math.abs(eyeTop.y - eyeBottom.y);

  const now = performance.now();
  if(eyeDist < 0.005 && now - lastBlinkTime > 300){
    blinkCount++;
    lastBlinkTime = now;
  }

  /* ---- Head movement ---- */
  const nose = lm[1];
  if(prevHeadX !== null){
    headMovement += Math.abs(nose.x - prevHeadX);
  }
  prevHeadX = nose.x;

  /* ---- Draw face points (debug) ---- */
  ctx.fillStyle="#00f0ff";
  lm.forEach(p=>{
    ctx.fillRect(p.x*canvas.width-1,p.y*canvas.height-1,2,2);
  });

  /* ---- Metrics per second ---- */
  blinkVal.innerText = blinkCount;
  moveVal.innerText = headMovement.toFixed(3);

  /* ---- Stress score (simple rule-based) ---- */
  let stress = 0;
  stress += blinkCount * 8;
  stress += headMovement * 400;
  stress = Math.min(100, Math.floor(stress));

  stressVal.innerText = stress;

  /* ---- reset every second ---- */
  if(now % 1000 < 16){
    blinkCount = 0;
    headMovement = 0;
  }
});

/* ========= FRAME LOOP ========= */
async function process(){
  await faceMesh.send({image:video});
  requestAnimationFrame(process);
}

/* ========= START ========= */
startCamera().then(process);
</script>

</body>
</html>
